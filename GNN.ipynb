{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb99f5c-702d-4e17-9298-0d7c86e4d5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6651\n",
      "Epoch 20, Loss: 0.4671\n",
      "Epoch 40, Loss: 0.4379\n",
      "Epoch 60, Loss: 0.4132\n",
      "Epoch 80, Loss: 0.3981\n",
      "Epoch 100, Loss: 0.3651\n",
      "Epoch 120, Loss: 0.3411\n",
      "Epoch 140, Loss: 0.3184\n",
      "Epoch 160, Loss: 0.3056\n",
      "Epoch 180, Loss: 0.2791\n",
      "Epoch 200, Loss: 0.2574\n",
      "Epoch 220, Loss: 0.2348\n",
      "Epoch 240, Loss: 0.2246\n",
      "Epoch 260, Loss: 0.1966\n",
      "Epoch 280, Loss: 0.1818\n",
      "Accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"diabetes.csv\")  # Ensure you have the dataset\n",
    "\n",
    "# Extract features and target\n",
    "X = df.drop(columns=[\"Outcome\"]).values  # Features\n",
    "y = df[\"Outcome\"].values  # Labels\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Create a similarity graph using k-nearest neighbors\n",
    "A = kneighbors_graph(X, n_neighbors=10, mode='connectivity')  # Create adjacency matrix\n",
    "G = nx.from_scipy_sparse_array(A)  # Convert to NetworkX graph\n",
    "\n",
    "# Extract edge index\n",
    "edge_index = torch.tensor(list(G.edges), dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create PyTorch Geometric data object\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = SAGEConv(hidden_dim, output_dim)\n",
    "        self.fc = Linear(output_dim, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# Initialize model with increased hidden_dim and extra layers\n",
    "model = GNN(input_dim=X.shape[1], hidden_dim=32, output_dim=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(300):  # Increased to 300 epochs\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        acc = (pred == data.y).sum().item() / len(data.y)\n",
    "        print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e8a6f2-0182-45c2-b1e8-8bc768bd3584",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3184595879.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install ipywidgets\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec3c1d-5645-480b-a17b-52212cdae023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
